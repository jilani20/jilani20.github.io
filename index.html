<h2> Jilani Shaik						763-321-1545 | jilani2420@gmail.com </h2>

<pre>
Professional Summary
Passionate Software Engineer with hands-on experience delivering robust, scalable ML solutions. Deeply specialized in Machine Learning and Generative AI (6+ years), with extensive experience across the Azure and Databricks ecosystems. Demonstrated success in translating complex data into actionable business insights by building and deploying ML pipelines and statistical analysis using Python and SQL, leveraging advanced frameworks such as PyTorch and TensorFlow. Proven leader guiding teams to develop machine learning models, APIs, and data pipelines to support business strategy.

Skills
•	Machine Learning & AI: Supervised/Unsupervised Learning, Neural Networks, Deep Learning (PyTorch, TensorFlow, Keras), Generative AI, LLMs (GPT, BERT), Transformer Architecture, Time Series Analysis/Forecasting (Prophet, ARIMA, DTW), Recommendation Systems, Causal Inference.
•	NLP: Text Cleaning, Tokenization, Normalization, Chunking, POS Tagging, Language Parsing/Quantification, TF-IDF, Word Embeddings (Word2Vec), CNN, RNN (LSTM), Sentiment Analysis, Chatbots, Text Generation, Fine-tuning (PEFT, LoRA, QLoRA, Prefix/Prompt Tuning), LangChain, LlamaIndex, Hugging Face.
•	MLOps & Deployment: ML Pipeline Design & Deployment, Model Selection/Evaluation/Monitoring, MLOps Processes, Data Drift Handling, A/B Testing, Docker, Kubernetes, GitHub CI/CD Pipelines, Azure DevOps.
•	Data Science & Analytics: Data Mining, Data Analysis/Cleaning, Statistics, Data Visualization (Tableau, Power BI), Feature Engineering, Model Selection/Evaluation/Deployment/Monitoring, Optuna, Extracting Actionable Insights.
•	Cloud Platforms: Azure (Expert), AWS (Familiar), GCP (Familiar).
•	Data Technologies: Databricks, PySpark, SQL, NoSQL Databases (Cosmos DB), ETL Pipelines, Data Governance, Stream Processing (Kafka), Delta Lake, Unity Catalog, Pinecone, FAISS.
•	Programming Languages: Python, Java, Scala.
•	Architecture Patterns: Machine Learning System Design, Distributed Training Architectures, Real-time/Batch Inference Architectures, Data Lakehouse Architecture for ML, Microservices, Event-Driven Architecture, Serverless.
•	Tools & Technologies: Azure Data Factory/Synapse/Stream Analytics, Jupyter, MLflow, Airflow, Grafana, Terraform.
•	Other Skills: Technical Leadership, Stakeholder/Vendor Management, Problem-Solving, Communication (Written & Verbal), Strategic Planning, Mentoring, Risk Management.
Work History
Optum | Principal Engineer | 01/2016 – Current
•	Leveraged deep understanding of healthcare payer data, risk stratification, and quality gap management to drive impactful data science and machine learning initiatives, uncovering critical insights.
•	Designed and implemented data environments, including feature stores, model registries, and scalable pipelines, to facilitate seamless transition of machine learning models from research to production.
•	Provided technical leadership for data infrastructure, strategically aligning it with the evolving needs of data science and Generative AI applications, ensuring data accessibility and quality for advanced analytical exploration.
•	Built robust data warehouses and efficient ETL/ELT pipelines, capable of handling high-velocity, volume, and variety data for feature engineering and model training.
•	Championed data quality and governance best practices within system designs, critical for building trustworthy ML models in healthcare.
•	Machine Learning for Healthcare | Machine Learning Lead Engineer
o	Developed a predictive model for hospital readmission risk leveraging diverse healthcare claims data, dynamic time warping (DTW) for temporal pattern analysis, and social determinants of health (SDOH), providing deep insights into patient risk factors.
o	Applied causal inference techniques to understand the potential impact of various factors on readmission, providing actionable insights for intervention strategies.
o	Managed the end-to-end ML lifecycle, from research to staging and production deployment, including tracking and monitoring.
o	Deployed a predictive model in distributed cluster to identify members for provider groups, measured with A/B tests, and gathered feedback for continuous improvement. Facilitated early launch of the In-Office Assessment Program (IOA) in mid-January annually.
o	Enhanced ensemble model accuracy to 95% by refining feature engineering and hyperparameter tuning, resulting in a 15% improvement in identifying critical medication gaps.
o	Utilized analytical classification models (LightGBM, XGBoost, Random Forest, Logistic Regression) to discern and target high-risk patient populations, deriving key insights for preventive care initiatives.
o	Converted business needs into ML applications to predict and manage member risk, aiming for measurable ROI through targeted in-person visits.
o	Extracted medical codes and suspect conditions from member charts using Azure AI Document Intelligence NLP libraries and transformers.
o	Utilized Spark MLlib and Python ML frameworks (Scikit-learn, NumPy, Optuna, Pandas, PyTorch, TensorFlow, Keras, SpaCy, Gensim, NLTK) for model development and predictions, following MLOps practices with Pipeline and MLflow, and enabling deployments via GitHub CI/CD pipelines and Docker.
o	Monitored models and Python notebooks using Unity Catalog, addressing data drift issues by updating incoming data pipelines, including schema evolution and erroneous label cleanup.
o	
•	Gen AI Clinical Decision Support | Machine Learning Lead Engineer
o	Indexed Member charts submitted by providers to Azure Search as Vector data.
o	Created a Generative AI feature using Azure, Retrieval Augmented Generation (RAG), and OpenAI to provide real-time, context-aware, and domain-specific answers to provider questions during member visits, improving product satisfaction by 20%.
o	
•	Batch and Real-time Data Processing | Lead Engineer
o	Designed and built a fast system using Spark and Kafka to process high-volume and velocity data into a Delta Lake and NoSQL, enabling real-time data analysis and insights for efficiently generating 500K customized PDFs.
o	Implemented a flexible cloud-native streaming framework supporting diverse Kafka consumption with dynamic business logic.
o	Implemented Azure Data Factory pipelines to Snowflake.
o	Implemented a scalable Medallion architecture on Delta Lake within Azure Databricks for diverse applications and stakeholders.
o	Utilized Unity Catalog for seamless data governance, auditing, and transfer across teams and projects.
o	Led the migration of big data systems from on-prem to Azure Databricks.
o	Optimized Spark cloud-native data pipelines by analyzing data characteristics and strategically tuning, achieving over 50% reduction in processing time.
CES Technology Services | Senior Technical Lead | 06/2015 – 12/2015
•	Provided technical guidance for projects, focusing on system design and data infrastructure to support analytical capabilities.
•	Designed and implemented layered Jersey REST services.
Bank of America | Sr. Analyst | 08/2014 – 05/2015
•	Designed and implemented robust data pipelines, integrating diverse data (e.g., loss forecasts, risk data) from various LOBs into Netezza for downstream analytics.
•	Managed end-to-end data pipelines with Oozie workflows, incorporating data quality checks.
•	Defined and implemented data sourcing standards within the Hadoop ecosystem, ensuring data quality.
•	Led efforts in sourcing data across business lines, conducting in-depth risk factor analysis to inform advanced data modeling and analytical initiatives.
Adroitent | Sr. Technical Lead | 02/2014 – 08/2014
•	Contributed to system design considerations for future search integration within medical research content.
•	Streamlined nightly content pull processes, improving data availability efficiency.
•	Designed core components to convert repository content into optimized Solr documents, enhancing search capabilities and content discoverability for insights.
ReThink IT Services | Technical Project Lead | 06/2011 – 02/2014
•	Led the development and implementation of a big data analytics platform, providing end users with relevant and meaningful data visualizations, enabling them to identify key patterns and trends and gain actionable intelligence for strategic planning and organizational enhancement.
•	Designed and deployed a robust, scalable big data infrastructure leveraging Hadoop (HDFS), NoSQL (HBase), and distributed computing frameworks.
•	Engineered end-to-end data ingestion pipelines, integrating structured and unstructured data sources.
•	Pioneered methodologies for large-scale data processing and analytical exploration using MapReduce paradigms and other distributed processing techniques to transform raw data into actionable insights, enabling multi-dimensional aggregation and comprehensive data exploration across vast datasets.
•	Developed advanced vendor behavior models by applying sophisticated analytical techniques, including forecasting, predictive modeling, and clustering methodologies, to derive meaningful vendor segmentation strategies from extensive transaction data.
•	Engineered and maintained data infrastructure utilizing HBase and Solr for efficient feature exploration.
•	Led development of scalable data ingestion processes using Spring Data and Batch APIs, creating efficient mechanisms for preparing and feeding large datasets into workflows by implementing data validation, and transformation for subsequent analysis and insights.
United Health Group | Sr. Software Engineer | 04/2010 – 06/2011
•	Supported critical business functions through application development and maintenance.

CTE | Software Engineer | 05/2006 – 04/2010
•	Developed reusable software (File Upload, Email Utility, Notifications) to optimize project timelines.

Education & Certifications
•	PG Program in Data Science and AI with Deep Learning from University of Texas at Austin.
•	Master of Computer Science from Osmania University - Hyderabad, India.
•	Bachelor of Mathematics from Acharya Nagarjuna University – Guntur, India.

</pre>
